<h1 align="center">Hi, I'm Hyoung-Kyu SongðŸ‘‹</h1>

<p align="center">
<a href="https://deepkyu.me">
<img src="https://raw.githubusercontent.com/deepkyu/deepkyu.github.io/master/static/img/background_cropped.png">
</a>
</p>

<h3 align="center">AI Researcher from South Korea <img src="https://em-content.zobj.net/thumbs/120/toss-face/342/flag-south-korea_1f1f0-1f1f7.png" width=16></h3>

<br/>

<p align="center">
    <a href="https://github.com/deepkyu">
    <img src="https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white">
    </a>
    <a href="https://www.youtube.com/@deepkyu">
    <img src="https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white">
    </a>
    <a href="https://www.linkedin.com/in/deepkyu">
    <img src="https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white">
    </a>
    <a href="https://twitter.com/deepkyu_song">
    <img src="https://img.shields.io/badge/Twitter-%231DA1F2.svg?style=for-the-badge&logo=Twitter&logoColor=white">
    </a>
    <a href="https://huggingface.co/deepkyu">
    <img src="./static/huggingface_unofficial.svg" height=28>
    </a>
</p>

<p align="center">
<a href="https://www.buymeacoffee.com/deepkyu" target="_blank"><img src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" alt="Buy Me A Coffee"></a>
</p>

<br/>

## News

### `ml-talking-face` demo is restored!

**2023. 12. 17.**
Our ml-talking-face demonstration has been restorted. Now, I'm using A10G instance from lambdalabs with my own expense...ðŸ«  I'll keep you posted on the status.

- [Hugging Face Demo `ml-talking-face`](https://huggingface.co/spaces/CVPR/ml-talking-face)
- [FAQ at Hugging Face model card](https://huggingface.co/deepkyu/ml-talking-face)
- [Paper](https://scholar.google.com/citations?view_op=view_citation&hl=en&citation_for_view=KR4U5YMAAAAJ:9yKSN-GCB0IC)


### The research for efficient stable diffusion, `BK-SDM`, is released!

**2023. 07. 19.**
I participated in stable diffusion model compression research in [Nota AI](https://www.nota.ai/), and published the paper, the model named [BK-SDM](https://arxiv.org/abs/2305.15798), with our teammates.
We compressed a conditional U-Net in stable diffusion with knowledge distillation method and found that the compressed model can sustain the original performance while finetuning with tiny dataset.
Please check our [code](https://github.com/Nota-NetsPresso/BK-SDM) and [other related work](https://huggingface.co/blog/sd_distillation) introduced by [Segmind](https://github.com/segmind/distill-sd).

<br/>
